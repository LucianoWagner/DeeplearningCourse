{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "76e63cad",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Turno 1 ---\n",
                        "\n",
                        "\n",
                        "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
                        "Prompt after formatting:\n",
                        "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
                        "\n",
                        "Current conversation:\n",
                        "\n",
                        "Human: Hola, soy Luciano, Analista Programador de Argentina.\n",
                        "AI:\u001b[0m\n",
                        "\n",
                        "\u001b[1m> Finished chain.\u001b[0m\n",
                        "Hola Luciano, Analista Programador de Argentina. Me alegra conocerte. ¿De qué parte de Argentina eres? ¿Te gusta trabajar con programación?\n",
                        "\n",
                        "--- Turno 2 (Llenando buffer de tokens) ---\n",
                        "\n",
                        "\n",
                        "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
                        "Prompt after formatting:\n",
                        "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
                        "\n",
                        "Current conversation:\n",
                        "Human: Hola, soy Luciano, Analista Programador de Argentina.\n",
                        "AI: Hola Luciano, Analista Programador de Argentina. Me alegra conocerte. ¿De qué parte de Argentina eres? ¿Te gusta trabajar con programación?\n",
                        "Human: Anotá mi agenda: \n",
                        "Mi agenda para mañana:\n",
                        "9:00 - Review de código con el equipo senior.\n",
                        "11:00 - Entrevista técnica en Ualá.\n",
                        "14:00 - Despliegue a producción de la nueva API.\n",
                        "16:00 - Gimnasio.\n",
                        "\n",
                        "AI:\u001b[0m\n",
                        "\n",
                        "\u001b[1m> Finished chain.\u001b[0m\n",
                        "Hola Luciano, me alegra que hayas agregado tus actividades a mi agenda. Me parece interesante que tengas una entrevista técnica en Ualá. Ualá es una empresa de pagos y finanzas en línea que se enfoca en la región de América Latina. ¿Has trabajado con alguna de sus tecnologías o plataformas en el pasado?\n",
                        "\n",
                        "En cuanto a tu día, parece que tienes un horario muy ocupado. ¿Puedes decirme un poco más sobre la nueva API que vas a desplegar a producción? ¿Es una API que has desarrollado tú mismo o es un proyecto que estás liderando en tu equipo?\n",
                        "\n",
                        "--- Turno 3 (Verificando memoria histórica) ---\n",
                        "\n",
                        "\n",
                        "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
                        "Prompt after formatting:\n",
                        "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
                        "\n",
                        "Current conversation:\n",
                        "System: Current summary:\n",
                        "Luciano, an Argentine programmer analyst, introduces himself to the AI. The AI responds and asks about Luciano's location in Argentina and his experience with programming. Luciano then adds his agenda for the next day to the AI's knowledge. The AI is interested in Luciano's upcoming interview at Ualá and asks about his experience with the company's technologies or platforms. The AI also inquires about the new API that Luciano will be deploying to production, asking if it's a project he developed himself or is leading in his team.\n",
                        "\n",
                        "New lines of conversation:\n",
                        "Luciano: Sí, he trabajado con algunas de sus tecnologías en el pasado. Me gustaría saber más sobre la estructura de la entrevista técnica. ¿Qué tipo de preguntas puedo esperar?\n",
                        "AI: La entrevista técnica en Ualá suele ser una evaluación de habilidades técnicas y experiencia en programación. Pueden hacer preguntas sobre algoritmos, estructuras de datos, diseño de sistemas y experiencia con lenguajes de programación específicos. ¿Tienes alguna experiencia con lenguajes de programación como Java o Python?\n",
                        "\n",
                        "New summary:\n",
                        "Luciano, an Argentine programmer analyst, introduces himself to the AI. The AI responds and asks about Luciano's location in Argentina and his experience with programming. Luciano then adds his agenda for the next day to the AI's knowledge. The AI is interested in Luciano's upcoming interview at Ualá and asks about his experience with the company's technologies or platforms. The AI also inquires about the new API that Luciano will be deploying to production, asking if it's a project he developed himself or is leading in his team. Luciano has worked with Ualá's technologies in the past and is preparing for a technical interview. The AI provides information about the type of questions Luciano can expect during the interview, including those about algorithms, data structures, system design, and specific programming languages such as Java or Python.\n",
                        "Human: ¿Qué recordás de mi perfil y qué planes tengo para mañana?\n",
                        "AI:\u001b[0m\n",
                        "\n",
                        "\u001b[1m> Finished chain.\u001b[0m\n",
                        "Recuerdo que eres Luciano, un analista de sistemas argentino. También recuerdo que mencionaste que tienes una entrevista en Ualá y que estás trabajando en un proyecto para desplegar una nueva API a producción. Además, mencionaste que has trabajado con algunas de las tecnologías de Ualá en el pasado. En cuanto a tus planes para mañana, recuerdo que mencionaste que tienes una agenda que incluye la entrevista en Ualá y posiblemente otros compromisos. ¿Quieres compartir más detalles sobre tu agenda para mañana?\n"
                    ]
                }
            ],
            "source": [
                "# =================================================================\n",
                "# 1. CONFIGURACIÓN DEL ENTORNO\n",
                "# =================================================================\n",
                "import os\n",
                "import warnings\n",
                "import langchain\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "# Parche de compatibilidad\n",
                "if not hasattr(langchain, 'verbose'):\n",
                "    langchain.verbose = False\n",
                "\n",
                "from langchain_groq import ChatGroq\n",
                "from langchain.chains import ConversationChain\n",
                "from langchain.memory import ConversationSummaryBufferMemory\n",
                "\n",
                "# Solución para errores de definición de Pydantic\n",
                "try:\n",
                "    from langchain_core.caches import BaseCache\n",
                "    from langchain_core.callbacks import Callbacks\n",
                "    ConversationSummaryBufferMemory.model_rebuild()\n",
                "except Exception:\n",
                "    pass\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# =================================================================\n",
                "# 2. INICIALIZACIÓN DEL MODELO Y MEMORIA\n",
                "# =================================================================\n",
                "\n",
                "# Usamos ChatGroq directamente para evitar errores de conteo de tokens\n",
                "llm = ChatGroq(\n",
                "    temperature=0.0,\n",
                "    model_name=\"llama-3.1-8b-instant\",\n",
                "    groq_api_key=os.environ.get(\"GROQ_API_KEY\")\n",
                ")\n",
                "\n",
                "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
                "\n",
                "conversation = ConversationChain(\n",
                "    llm=llm, \n",
                "    memory=memory,\n",
                "    verbose=True \n",
                ")\n",
                "\n",
                "# =================================================================\n",
                "# 3. PRUEBA DE LA CONVERSACIÓN\n",
                "# =================================================================\n",
                "\n",
                "print(\"--- Turno 1 ---\")\n",
                "print(conversation.predict(input=\"Hola, soy Luciano, Analista Programador de Argentina.\"))\n",
                "\n",
                "print(\"\\n--- Turno 2 (Llenando buffer de tokens) ---\")\n",
                "texto_largo = \"\"\"\n",
                "Mi agenda para mañana:\n",
                "9:00 - Review de código con el equipo senior.\n",
                "11:00 - Entrevista técnica en Ualá.\n",
                "14:00 - Despliegue a producción de la nueva API.\n",
                "16:00 - Gimnasio.\n",
                "\"\"\"\n",
                "print(conversation.predict(input=f\"Anotá mi agenda: {texto_largo}\"))\n",
                "\n",
                "print(\"\\n--- Turno 3 (Verificando memoria histórica) ---\")\n",
                "print(conversation.predict(input=\"¿Qué recordás de mi perfil y qué planes tengo para mañana?\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "009ca588",
            "metadata": {},
            "source": [
                "¿Cómo funcionó en tu código?\n",
                "Fijate en lo que salió en tu consola en el Turno 3:\n",
                "\n",
                "Superaste el límite: Como pusimos max_token_limit=100 (un límite muy bajo), en cuanto le pasaste la agenda larga, el programa dijo: \"Upa, si guardo todo esto tal cual, me paso de 100 tokens\".\n",
                "El Resumen automático: Antes de responder, LangChain llamó a la IA por detrás y le pidió: \"Resumime todo lo que hablamos hasta ahora\".\n",
                "El nuevo Prompt: Si miras el Turno 3, verás que dice: System: Current summary: Luciano, an Argentine programmer analyst... La IA ya no está leyendo \"Hola soy Luciano...\", está leyendo el resumen condensado.\n",
                "¿Por qué esto es mejor que otras memorias?\n",
                "Si usás ConversationBufferMemory (la básica): Tarde o temprano te quedás sin memoria o la cuenta de la API se va a las nubes porque el historial crece infinitamente.\n",
                "Si usás ConversationSummaryBufferMemory: Nunca te pasás del límite. La conversación puede durar 10 horas, que la IA siempre va a tener un resumen de lo importante y las últimas 2 o 3 frases exactas para mantener el contexto fluido."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
